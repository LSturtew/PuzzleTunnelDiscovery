#!/usr/bin/env python3

'''
Print the pair (edge) of RDT trees that share the same sample in the same PreDefined sample Set (PDS).
These files are generated by `se3solver.py solve --samset` or `se3solver.py solve --samset2`

Note:
    This application does NOT (and ARE NOT ABLE TO) check the same PDS is used.
    User is responsible to guarantee this.
'''

import sys, os
sys.path.append(os.getcwd())

import argparse
import numpy as np
from scipy.io import loadmat
import h5py
import scipy.sparse as sparse
from progressbar import progressbar
from pipeline import matio

def print_edge(args):
    OPENSPACE_FLAG = 1
    if args.pdsflags is not None:
        QF = np.load(args.pdsflags)['QF']
    else:
        QF = None
    f = h5py.File(args.out, mode='a')
    '''
    # old code
    E = None
    r = 0
    for fn in progressbar(args.files):
        rowdata = loadmat(fn)['C']
        if E is None:
            E = np.zeros((len(args.files), rowdata.shape[1]), dtype=np.int8)
        E[r] = rowdata.todense()
        r += 1
    root_from, pds_to = E.nonzero()
    forest_edge = np.transpose(np.array([root_from, pds_to], dtype=np.int32))
    matio.hdf5_overwrite(f, 'EE', forest_edge)
    f.flush()
    del forest_edge
    '''
    N = len(args.files) # N: number of roots
    K = None            # K: PDS size
    ds_Edense = None
    total_nz = 0
    for i,fn in enumerate(progressbar(args.files)):
        row_data = matio.load(fn)['C'].todense()
        if K is None:
            K = row_data.shape[1]
        if ds_Edense is None:
            ds_Edense = matio.hdf5_open(f, 'Edense', shape=(N, K),
                                        dtype=np.int8,
                                        chunks=True,
                                        compression='lzf')
        # Performance ?
        ds_Edense.write_direct(row_data, source_sel=np.s_[:, :], dest_sel=np.s_[i, :])
        total_nz += len(row_data.nonzero()[0])
    f.flush()
    print("Total number of NZ elemtns {}".format(total_nz))

    inter_tree_dtype = np.uint32 if K < np.iinfo(np.uint32).max else np.uint64
    inter_tree_max = np.iinfo(inter_tree_dtype).max
    ITE = inter_tree_edge = np.zeros((N, N), dtype=inter_tree_dtype)

    col_data = np.zeros((N, 1), dtype=np.int8)
    # Iterate through all PDS milestones, to construct ITE
    # ITE is O(N^2) which is managable in memory
    for i in progressbar(range(K)):
        col = K - 1 - i # from K-1 to 0, so ITE keeps the smallest PDS milestone
        ds_Edense.read_direct(col_data, source_sel=np.s_[:, col], dest_sel=np.s_[:, 0])
        if np.sum(col_data) < 2:
            continue
        # trees connected by PDS milestone col
        star_from_pds = col_data.nonzero()[0]
        # Keep the edge number low by NOT constructing a clique
        # We are supposed to trim the duplicated path in forest_dijkstra
        edge_from = star_from_pds[:-1]
        edge_to = star_from_pds[1:]
        '''
        We uses 0 to represent 'No edges', so PDS Milestone I will be denoted as I+1
        '''
        ITE[edge_from, edge_to] = col + 1

    roots_to_open = set()
    if QF is not None:
        nz = np.where(QF & OPENSPACE_FLAG != 0)[0]
        for i in progressbar(nz):
            ds_Edense.read_direct(col_data, source_sel=np.s_[:, i], dest_sel=np.s_[:, 0])
            rows = col_data.nonzero()[0].tolist()
            roots_to_open.update(rows)
        roots_to_open_list = np.array(list(roots_to_open), dtype=ITE.dtype)
        matio.hdf5_overwrite(f, 'OpenTree', roots_to_open_list)

    edge_from, edge_to = ITE.nonzero()
    edge = np.transpose(np.array([edge_from, edge_to, ITE[edge_from, edge_to]], dtype=ITE.dtype))
    matio.hdf5_overwrite(f, 'Etup', edge)

    '''
    # old code
    cws = E.sum(axis=0)
    nv = cws.shape[0]
    Edense = np.zeros((len(args.files), len(args.files)), dtype=np.int32)
    for i in progressbar(range(nv)):
        s = cws[i]
        if s < 2:
            continue
        rows = np.nonzero(E[:,i])[0].tolist()
        edge_from = rows[:-1]
        edge_to = rows[1:]
        Edense[edge_from, edge_to] = i
    roots_to_open = set()
    if QF is not None:
        for i in progressbar(range(nv)):
            if QF[i] & OPENSPACE_FLAG == 0:
                continue
            rows = np.nonzero(E[:,i])[0].tolist()
            roots_to_open.update(rows)
    del cws
    del E
    # edge = np.transpose(np.array([edge_from, edge_to], dtype=np.int32))
    # print("Uniquing the edge pairs")
    # edge = np.unique(edge, axis=0)
    # del edge_from
    # del edge_to
    edge_from, edge_to = Edense.nonzero()
    roots_to_open_list = np.array(list(roots_to_open), dtype=np.int64)
    """
    if len(roots_to_open) >= 2:
        # Add a chain that connects all roots with openspace leaf.
        # This is not enough for path planning, but good enough for disjoint set algorithm
        edge_from = np.append(edge_from, roots_to_open_list[:-1])
        edge_to = np.append(edge_to, roots_to_open_list[1:])
    """
    edge = np.transpose(np.array([edge_from, edge_to, Edense[edge_from, edge_to]], dtype=np.int32))
    #savemat(args.out, dict(E=edge, FE=forest_edge), do_compression=True)
    matio.hdf5_overwrite(f, 'E', edge)
    matio.hdf5_overwrite(f, 'OpenTree', roots_to_open_list)
    '''
    f.close()

def main():
    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('files', help='ssc-*.mat file', nargs='+')
    parser.add_argument('--out', help='output edge file in .hdf5', required=True)
    parser.add_argument('--pdsflags', help='File that stores PDS Flags, usually in the same npz file that also stores PDS', default=None)
    args = parser.parse_args()
    if not args.out.endswith('.hdf5'):
        print("--out requires hdf5 extension")
        return
    print_edge(args)

if __name__ == '__main__':
    import cProfile
    cProfile.run('main()')
